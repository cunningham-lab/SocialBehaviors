  0%|          | 0/5000 [00:00<?, ?it/s]iter 0 loss 924134.33:   0%|          | 0/5000 [00:00<?, ?it/s]iter 0 loss 924134.33:   2%|▏         | 100/5000 [00:00<00:29, 166.69it/s]iter 0 loss 924134.33:   2%|▏         | 100/5000 [00:20<00:29, 166.69it/s]iter 100 loss 188926.60:   2%|▏         | 100/5000 [01:06<00:29, 166.69it/s]iter 100 loss 188926.60:   4%|▍         | 200/5000 [01:06<16:08,  4.96it/s] iter 200 loss 140585.96:   4%|▍         | 200/5000 [02:04<16:08,  4.96it/s]iter 200 loss 140585.96:   6%|▌         | 300/5000 [02:04<24:39,  3.18it/s]iter 300 loss 130696.94:   6%|▌         | 300/5000 [02:57<24:39,  3.18it/s]iter 300 loss 130696.94:   8%|▊         | 400/5000 [02:57<29:13,  2.62it/s]iter 400 loss 125273.35:   8%|▊         | 400/5000 [03:57<29:13,  2.62it/s]iter 400 loss 125273.35:  10%|█         | 500/5000 [03:57<33:21,  2.25it/s]iter 500 loss 120676.20:  10%|█         | 500/5000 [04:53<33:21,  2.25it/s]iter 500 loss 120676.20:  12%|█▏        | 600/5000 [04:53<35:16,  2.08it/s]iter 600 loss 117100.43:  12%|█▏        | 600/5000 [05:51<35:16,  2.08it/s]iter 600 loss 117100.43:  14%|█▍        | 700/5000 [05:51<36:29,  1.96it/s]iter 700 loss 113177.74:  14%|█▍        | 700/5000 [06:47<36:29,  1.96it/s]iter 700 loss 113177.74:  16%|█▌        | 800/5000 [06:47<36:48,  1.90it/s]iter 800 loss 108440.17:  16%|█▌        | 800/5000 [07:42<36:48,  1.90it/s]iter 800 loss 108440.17:  18%|█▊        | 900/5000 [07:42<36:19,  1.88it/s]iter 900 loss 105360.63:  18%|█▊        | 900/5000 [08:36<36:19,  1.88it/s]iter 900 loss 105360.63:  20%|██        | 1000/5000 [08:36<35:41,  1.87it/s]iter 1000 loss 103337.09:  20%|██        | 1000/5000 [09:30<35:41,  1.87it/s]iter 1000 loss 103337.09:  22%|██▏       | 1100/5000 [09:30<34:55,  1.86it/s]iter 1100 loss 101862.80:  22%|██▏       | 1100/5000 [10:28<34:55,  1.86it/s]iter 1100 loss 101862.80:  24%|██▍       | 1200/5000 [10:28<34:51,  1.82it/s]iter 1200 loss 100264.45:  24%|██▍       | 1200/5000 [11:25<34:51,  1.82it/s]iter 1200 loss 100264.45:  26%|██▌       | 1300/5000 [11:25<34:12,  1.80it/s]iter 1300 loss 99351.59:  26%|██▌       | 1300/5000 [12:20<34:12,  1.80it/s] iter 1300 loss 99351.59:  28%|██▊       | 1400/5000 [12:20<33:10,  1.81it/s]iter 1400 loss 98694.36:  28%|██▊       | 1400/5000 [13:20<33:10,  1.81it/s]iter 1400 loss 98694.36:  30%|███       | 1500/5000 [13:20<33:02,  1.77it/s]iter 1500 loss 98295.62:  30%|███       | 1500/5000 [14:16<33:02,  1.77it/s]iter 1500 loss 98295.62:  32%|███▏      | 1600/5000 [14:16<32:07,  1.76it/s]iter 1600 loss 98016.78:  32%|███▏      | 1600/5000 [15:15<32:07,  1.76it/s]iter 1600 loss 98016.78:  34%|███▍      | 1700/5000 [15:15<31:33,  1.74it/s]iter 1700 loss 97834.92:  34%|███▍      | 1700/5000 [16:10<31:33,  1.74it/s]iter 1700 loss 97834.92:  36%|███▌      | 1800/5000 [16:10<30:13,  1.76it/s]iter 1800 loss 97695.84:  36%|███▌      | 1800/5000 [17:04<30:13,  1.76it/s]iter 1800 loss 97695.84:  38%|███▊      | 1900/5000 [17:04<28:44,  1.80it/s]iter 1900 loss 97531.88:  38%|███▊      | 1900/5000 [17:57<28:44,  1.80it/s]iter 1900 loss 97531.88:  40%|████      | 2000/5000 [17:57<27:26,  1.82it/s]iter 2000 loss 97265.87:  40%|████      | 2000/5000 [18:50<27:26,  1.82it/s]iter 2000 loss 97265.87:  42%|████▏     | 2100/5000 [18:50<26:14,  1.84it/s]iter 2100 loss 97165.04:  42%|████▏     | 2100/5000 [19:44<26:14,  1.84it/s]iter 2100 loss 97165.04:  44%|████▍     | 2200/5000 [19:44<25:21,  1.84it/s]iter 2200 loss 97086.37:  44%|████▍     | 2200/5000 [20:42<25:21,  1.84it/s]iter 2200 loss 97086.37:  46%|████▌     | 2300/5000 [20:42<24:58,  1.80it/s]iter 2300 loss 97018.09:  46%|████▌     | 2300/5000 [21:38<24:58,  1.80it/s]iter 2300 loss 97018.09:  48%|████▊     | 2400/5000 [21:38<24:05,  1.80it/s]iter 2400 loss 96955.94:  48%|████▊     | 2400/5000 [22:32<24:05,  1.80it/s]iter 2400 loss 96955.94:  50%|█████     | 2500/5000 [22:32<22:53,  1.82it/s]iter 2500 loss 96897.70:  50%|█████     | 2500/5000 [23:25<22:53,  1.82it/s]iter 2500 loss 96897.70:  52%|█████▏    | 2600/5000 [23:25<21:47,  1.84it/s]iter 2600 loss 96842.07:  52%|█████▏    | 2600/5000 [24:22<21:47,  1.84it/s]iter 2600 loss 96842.07:  54%|█████▍    | 2700/5000 [24:22<21:12,  1.81it/s]iter 2700 loss 96788.04:  54%|█████▍    | 2700/5000 [25:20<21:12,  1.81it/s]iter 2700 loss 96788.04:  56%|█████▌    | 2800/5000 [25:20<20:33,  1.78it/s]iter 2800 loss 96734.46:  56%|█████▌    | 2800/5000 [26:17<20:33,  1.78it/s]iter 2800 loss 96734.46:  58%|█████▊    | 2900/5000 [26:17<19:41,  1.78it/s]iter 2900 loss 96680.11:  58%|█████▊    | 2900/5000 [27:14<19:41,  1.78it/s]iter 2900 loss 96680.11:  60%|██████    | 3000/5000 [27:14<18:48,  1.77it/s]iter 3000 loss 96624.02:  60%|██████    | 3000/5000 [28:07<18:48,  1.77it/s]iter 3000 loss 96624.02:  62%|██████▏   | 3100/5000 [28:07<17:33,  1.80it/s]iter 3100 loss 96567.85:  62%|██████▏   | 3100/5000 [29:00<17:33,  1.80it/s]iter 3100 loss 96567.85:  64%|██████▍   | 3200/5000 [29:00<16:25,  1.83it/s]iter 3200 loss 96513.38:  64%|██████▍   | 3200/5000 [29:53<16:25,  1.83it/s]iter 3200 loss 96513.38:  66%|██████▌   | 3300/5000 [29:53<15:20,  1.85it/s]iter 3300 loss 96460.77:  66%|██████▌   | 3300/5000 [30:45<15:20,  1.85it/s]iter 3300 loss 96460.77:  68%|██████▊   | 3400/5000 [30:45<14:19,  1.86it/s]iter 3400 loss 96409.52:  68%|██████▊   | 3400/5000 [31:38<14:19,  1.86it/s]iter 3400 loss 96409.52:  70%|███████   | 3500/5000 [31:38<13:22,  1.87it/s]iter 3500 loss 96358.96:  70%|███████   | 3500/5000 [32:32<13:22,  1.87it/s]iter 3500 loss 96358.96:  72%|███████▏  | 3600/5000 [32:32<12:27,  1.87it/s]iter 3600 loss 96308.46:  72%|███████▏  | 3600/5000 [33:24<12:27,  1.87it/s]iter 3600 loss 96308.46:  74%|███████▍  | 3700/5000 [33:24<11:32,  1.88it/s]iter 3700 loss 96257.50:  74%|███████▍  | 3700/5000 [34:18<11:32,  1.88it/s]iter 3700 loss 96257.50:  76%|███████▌  | 3800/5000 [34:18<10:39,  1.88it/s]iter 3800 loss 96205.60:  76%|███████▌  | 3800/5000 [35:10<10:39,  1.88it/s]iter 3800 loss 96205.60:  78%|███████▊  | 3900/5000 [35:10<09:41,  1.89it/s]iter 3900 loss 96152.20:  78%|███████▊  | 3900/5000 [36:02<09:41,  1.89it/s]iter 3900 loss 96152.20:  80%|████████  | 4000/5000 [36:02<08:46,  1.90it/s]iter 4000 loss 96096.55:  80%|████████  | 4000/5000 [36:54<08:46,  1.90it/s]iter 4000 loss 96096.55:  82%|████████▏ | 4100/5000 [36:54<07:53,  1.90it/s]iter 4100 loss 96038.79:  82%|████████▏ | 4100/5000 [37:47<07:53,  1.90it/s]iter 4100 loss 96038.79:  84%|████████▍ | 4200/5000 [37:47<06:59,  1.91it/s]iter 4200 loss 95975.02:  84%|████████▍ | 4200/5000 [38:41<06:59,  1.91it/s]iter 4200 loss 95975.02:  86%|████████▌ | 4300/5000 [38:41<06:11,  1.89it/s]iter 4300 loss 95900.01:  86%|████████▌ | 4300/5000 [39:44<06:11,  1.89it/s]iter 4300 loss 95900.01:  88%|████████▊ | 4400/5000 [39:44<05:36,  1.78it/s]iter 4400 loss 95829.26:  88%|████████▊ | 4400/5000 [40:45<05:36,  1.78it/s]iter 4400 loss 95829.26:  90%|█████████ | 4500/5000 [40:45<04:47,  1.74it/s]iter 4500 loss 95671.48:  90%|█████████ | 4500/5000 [41:44<04:47,  1.74it/s]iter 4500 loss 95671.48:  92%|█████████▏| 4600/5000 [41:44<03:52,  1.72it/s]iter 4600 loss 95565.20:  92%|█████████▏| 4600/5000 [42:44<03:52,  1.72it/s]iter 4600 loss 95565.20:  94%|█████████▍| 4700/5000 [42:44<02:55,  1.71it/s]iter 4700 loss 95494.21:  94%|█████████▍| 4700/5000 [43:52<02:55,  1.71it/s]iter 4700 loss 95494.21:  96%|█████████▌| 4800/5000 [43:52<02:03,  1.62it/s]iter 4800 loss 95429.66:  96%|█████████▌| 4800/5000 [44:59<02:03,  1.62it/s]iter 4800 loss 95429.66:  98%|█████████▊| 4900/5000 [44:59<01:02,  1.59it/s]iter 4900 loss 95367.73:  98%|█████████▊| 4900/5000 [46:03<01:02,  1.59it/s]iter 4900 loss 95367.73: 100%|██████████| 5000/5000 [46:03<00:00,  1.58it/s]
Experiment params:
{'job_name': 'single/v01_K4', 'downsample_n': 1, 'load_model': False, 'load_model_dir': '', 'train_model': True, 'pbar_update_interval': 100, 'K': 4, 'n_x': 3, 'n_y': 3, 'list_of_num_iters': [5000], 'list_of_lr': [0.005], 'video_clip_start': 0, 'video_clip_end': 1, 'sample_T': 1000}
Making result directory...
Saving to rlst_dir:  /Users/leah/Columbia/courses/19summer/SocialBehavior/rslts/single/v01_K4_D190819_135801
start training

inferiring most likely states...
0 step prediction
Did not provide memory information
5 step prediction
begin saving...
Finish running!
